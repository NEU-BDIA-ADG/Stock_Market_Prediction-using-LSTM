{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting tweets using tweeepy and aylienapiclient\n",
    "\n",
    "Required Packages:\n",
    "1. tweepy\n",
    "2. csv\n",
    "3. matplotlib\n",
    "4. aylien-apiclient==0.1.0  #!pip install aylien-apiclient==0.1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For collecting tweets with twitter API i.e. tweepy, you need to have api credentials and for getting credentials you need to sign in with twitter. Same for AylienApiClient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many Tweets do you want to analyze? \n",
      "70\n",
      "What user would you like to search for? \n",
      "AAPL\n",
      "--- Gathered Tweets \n",
      "\n",
      "--- Opened a CSV file to store the results of your sentiment analysis... \n",
      "\n",
      "2018-04-21 17:25:18\n",
      "Analyzed Tweet 1\n",
      "2018-04-21 17:22:29\n",
      "Analyzed Tweet 2\n",
      "2018-04-21 17:18:01\n",
      "Analyzed Tweet 3\n",
      "2018-04-21 17:15:08\n",
      "Analyzed Tweet 4\n",
      "2018-04-21 17:04:42\n",
      "Analyzed Tweet 5\n",
      "2018-04-21 17:02:39\n",
      "Analyzed Tweet 6\n",
      "2018-04-21 17:01:51\n",
      "Analyzed Tweet 7\n",
      "2018-04-21 17:00:42\n",
      "Analyzed Tweet 8\n",
      "2018-04-21 16:54:30\n",
      "Analyzed Tweet 9\n",
      "2018-04-21 16:40:25\n",
      "Analyzed Tweet 10\n",
      "2018-04-21 16:37:04\n",
      "Analyzed Tweet 11\n",
      "2018-04-21 16:36:51\n",
      "Analyzed Tweet 12\n",
      "2018-04-21 16:33:26\n",
      "Analyzed Tweet 13\n",
      "2018-04-21 16:30:13\n",
      "Analyzed Tweet 14\n",
      "2018-04-21 16:28:30\n",
      "Analyzed Tweet 15\n",
      "2018-04-21 16:25:42\n",
      "Analyzed Tweet 16\n",
      "2018-04-21 16:21:02\n",
      "Analyzed Tweet 17\n",
      "2018-04-21 16:14:08\n",
      "Analyzed Tweet 18\n",
      "2018-04-21 16:11:12\n",
      "Analyzed Tweet 19\n",
      "2018-04-21 16:08:39\n",
      "Analyzed Tweet 20\n",
      "2018-04-21 16:07:53\n",
      "Analyzed Tweet 21\n",
      "2018-04-21 16:07:49\n",
      "Analyzed Tweet 22\n",
      "2018-04-21 16:07:28\n",
      "Analyzed Tweet 23\n",
      "2018-04-21 16:05:24\n",
      "Analyzed Tweet 24\n",
      "2018-04-21 16:01:13\n",
      "Analyzed Tweet 25\n",
      "2018-04-21 16:00:53\n",
      "Analyzed Tweet 26\n",
      "2018-04-21 16:00:02\n",
      "Analyzed Tweet 27\n",
      "2018-04-21 16:00:01\n",
      "Analyzed Tweet 28\n",
      "2018-04-21 15:59:45\n",
      "Analyzed Tweet 29\n",
      "2018-04-21 15:54:03\n",
      "Analyzed Tweet 30\n",
      "2018-04-21 15:50:47\n",
      "Analyzed Tweet 31\n",
      "2018-04-21 15:50:41\n",
      "Analyzed Tweet 32\n",
      "2018-04-21 15:41:18\n",
      "Analyzed Tweet 33\n",
      "2018-04-21 15:35:59\n",
      "Analyzed Tweet 34\n",
      "2018-04-21 15:32:30\n",
      "Analyzed Tweet 35\n",
      "2018-04-21 15:30:50\n",
      "Analyzed Tweet 36\n",
      "2018-04-21 15:30:13\n",
      "Analyzed Tweet 37\n",
      "2018-04-21 15:30:08\n",
      "Analyzed Tweet 38\n",
      "2018-04-21 15:29:19\n",
      "Analyzed Tweet 39\n",
      "2018-04-21 15:27:46\n",
      "Analyzed Tweet 40\n",
      "2018-04-21 15:21:59\n",
      "Analyzed Tweet 41\n",
      "2018-04-21 15:20:04\n",
      "Analyzed Tweet 42\n",
      "2018-04-21 15:17:04\n",
      "Analyzed Tweet 43\n",
      "2018-04-21 15:05:07\n",
      "Analyzed Tweet 44\n",
      "2018-04-21 14:58:10\n",
      "Analyzed Tweet 45\n",
      "2018-04-21 14:56:28\n",
      "Analyzed Tweet 46\n",
      "2018-04-21 14:54:48\n",
      "Analyzed Tweet 47\n",
      "2018-04-21 14:51:50\n",
      "Analyzed Tweet 48\n",
      "2018-04-21 14:46:59\n",
      "Analyzed Tweet 49\n",
      "2018-04-21 14:45:12\n",
      "Analyzed Tweet 50\n",
      "2018-04-21 14:38:30\n",
      "Analyzed Tweet 51\n",
      "2018-04-21 14:36:03\n",
      "Analyzed Tweet 52\n",
      "2018-04-21 14:30:14\n",
      "Analyzed Tweet 53\n",
      "2018-04-21 14:30:05\n",
      "Analyzed Tweet 54\n",
      "2018-04-21 14:28:01\n",
      "Analyzed Tweet 55\n",
      "2018-04-21 14:20:19\n",
      "Analyzed Tweet 56\n",
      "2018-04-21 14:15:09\n",
      "Analyzed Tweet 57\n",
      "2018-04-21 14:12:02\n",
      "Analyzed Tweet 58\n",
      "2018-04-21 14:07:33\n",
      "Analyzed Tweet 59\n",
      "2018-04-21 14:07:23\n",
      "Analyzed Tweet 60\n",
      "2018-04-21 14:04:46\n",
      "Analyzed Tweet 61\n",
      "2018-04-21 14:03:13\n",
      "Analyzed Tweet 62\n",
      "2018-04-21 14:00:13\n",
      "Analyzed Tweet 63\n",
      "2018-04-21 14:00:00\n",
      "Analyzed Tweet 64\n",
      "2018-04-21 13:57:45\n",
      "Analyzed Tweet 65\n",
      "2018-04-21 13:55:49\n",
      "Analyzed Tweet 66\n",
      "2018-04-21 13:54:53\n",
      "Analyzed Tweet 67\n",
      "2018-04-21 13:53:31\n"
     ]
    },
    {
     "ename": "HttpError",
     "evalue": "<HttpError 429 when requesting https://api.aylien.com/api/v1/sentiment returned \"Too Many Requests\">",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHttpError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-48d332644604>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     70\u001b[0m            \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m        \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSentiment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtidy_tweet\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m        csv_writer.writerow({\n\u001b[0;32m     74\u001b[0m            \u001b[1;34m'Time'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mtweettime\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\aylienapiclient\\textapi.py\u001b[0m in \u001b[0;36mSentiment\u001b[1;34m(self, options)\u001b[0m\n\u001b[0;32m    363\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mMissingParameterError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'You must either provide url or text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 365\u001b[1;33m     \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_executeRequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'sentiment'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\aylienapiclient\\textapi.py\u001b[0m in \u001b[0;36m_executeRequest\u001b[1;34m(self, endpoint, params)\u001b[0m\n\u001b[0;32m    422\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 424\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mHttpError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muri\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    425\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mHttpError\u001b[0m: <HttpError 429 when requesting https://api.aylien.com/api/v1/sentiment returned \"Too Many Requests\">"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import csv\n",
    "import tweepy\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from collections import Counter\n",
    "from aylienapiclient import textapi\n",
    "\n",
    "if sys.version_info[0] < 3:\n",
    "   input = raw_input\n",
    "\n",
    "## Twitter credentials\n",
    "consumer_key = \"buD36prPWXKOHJhtsq1yhj4d5\"\n",
    "consumer_secret = \"LsjuTUH1mchDCfxLHcZkUzPWFvikZLAAj5uaLuxZZ0lTtPMTrV\"\n",
    "access_token = \"973597389226471424-4HI6QmITahXeyfg2U9cos1wJhtwUZdb\"\n",
    "access_token_secret = \"YjtNFgmWcF5mUghtMCrwQADk6c2wToT84gSl1MGqh3Pvz\"\n",
    "\n",
    "## AYLIEN credentials\n",
    "application_id = \"4b85d18c\"\n",
    "application_key = \"07a17f39487276de81dafe3114335355\"\n",
    "\n",
    "## set up an instance of Tweepy\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "## set up an instance of the AYLIEN Text API\n",
    "client = textapi.Client(application_id, application_key)\n",
    "\n",
    "## search Twitter for something that interests you\n",
    "number = input(\"How many Tweets do you want to analyze? \\n\")\n",
    "userName = input(\"What user would you like to search for? \\n\")\n",
    "\n",
    "user = api.get_user(userName)\n",
    "\n",
    "results = api.search(\n",
    "   lang=\"en\",\n",
    "   q=\"$\" + userName+ \" -rt\",\n",
    "   count=number,\n",
    "   result_type=\"recent\"\n",
    ")\n",
    "\n",
    "\n",
    "systime = time.strftime(\"%Y%m%d\")\n",
    "\n",
    "print(\"--- Gathered Tweets \\n\")\n",
    "\n",
    "## open a csv file to store the Tweets and their sentiment \n",
    "file_name = 'Sentiment_Analysis_of_{}_Tweets_About_{}_{}.csv'.format(number, userName,systime)\n",
    "\n",
    "with open(file_name, 'w', newline='') as csvfile:\n",
    "   csv_writer = csv.DictWriter(\n",
    "       f=csvfile,\n",
    "       fieldnames=[\"Time\",\"Tweet\", \"Sentiment\"]\n",
    "   )\n",
    "   csv_writer.writeheader()\n",
    "\n",
    "   print(\"--- Opened a CSV file to store the results of your sentiment analysis... \\n\")\n",
    "\n",
    "## tidy up the Tweets and send each to the AYLIEN Text API\n",
    "   for c, result in enumerate(results, start=1):\n",
    "       tweet = result.text\n",
    "       tweettime = result.created_at\n",
    "       print(tweettime)\n",
    "       tidy_tweet = tweet.strip().encode('ascii', 'ignore')\n",
    "\n",
    "       if len(tweet) == 0:\n",
    "           print('Empty Tweet')\n",
    "           continue\n",
    "\n",
    "       response = client.Sentiment({'text': tidy_tweet})\n",
    "       csv_writer.writerow({\n",
    "           'Time' : tweettime,\n",
    "           'Tweet': response['text'],\n",
    "           'Sentiment': response['polarity']\n",
    "           \n",
    "       })\n",
    "\n",
    "       print(\"Analyzed Tweet {}\".format(c))\n",
    "\n",
    "## count the data in the Sentiment column of the CSV file \n",
    "with open(file_name, 'r') as data:\n",
    "   counter = Counter()\n",
    "   for row in csv.DictReader(data):\n",
    "       counter[row['Sentiment']] += 1\n",
    "\n",
    "   positive = counter['positive']\n",
    "   negative = counter['negative']\n",
    "   neutral = counter['neutral']\n",
    "\n",
    "## declare the variables for the pie chart, using the Counter variables for \"sizes\"\n",
    "colors = ['green', 'red', 'grey']\n",
    "sizes = [positive, negative, neutral]\n",
    "labels = 'Positive', 'Negative', 'Neutral'\n",
    "\n",
    "## use matplotlib to plot the chart\n",
    "plt.pie(\n",
    "   x=sizes,\n",
    "   shadow=True,\n",
    "   colors=colors,\n",
    "   labels=labels,\n",
    "   startangle=90\n",
    ")\n",
    "\n",
    "plt.title(\"Sentiment of {} Tweets about {} from {}\".format(number, userName,tweettime))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The tweets are collected in a csv in the same folder with columns as Tweet, Sentiment and datetime of tweet when it was created. The time is server time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
